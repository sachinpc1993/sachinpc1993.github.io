---
---


@inproceedings{magnossaoangel2025effectsLLMPersonas,
author = {Magnoss\~{a}o de Paula, Angel Felipe and Culpepper, J. Shane and Moffat, Alistair and Pathiyan Cherumanal, Sachin and Scholer, Falk and Trippas, Johanne},
title = {The Effects of Demographic Instructions on LLM Personas},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730255},
doi = {10.1145/3726302.3730255},
abstract = {Social media platforms must filter sexist content in compliance with governmental regulations. Current machine learning approaches can reliably detect sexism based on standardized definitions, but often neglect the subjective nature of sexist language and fail to consider individual users' perspectives. To address this gap, we adopt a perspectivist approach, retaining diverse annotations rather than enforcing gold-standard labels or their aggregations, allowing models to account for personal or group-specific views of sexism. Using demographic data from Twitter, we employ large language models (LLMs) to personalize the identification of sexism. Our empirical results show that OpenAI's LLMs (GPT-3.5, GPT-4, and GPT-4o) and two open-source LLMs (Mistral and Qwen) exhibit higher Krippendorff's alpha label agreement with female annotators than with male annotators. As well, each LLM presents higher Krippendorff's alpha agreement with a specific annotator age group. We then sought to counter these trends by providing ''persona'' instructions as part of the LLM prompt, with somewhat surprising outcomes, highlighting the potential of user-centered perspectivist methods to improve content moderation systems.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3045-3049},
numpages = {5},
keywords = {bias, evaluation, large language models, perspectivism, sexism detection, unbiased methods},
location = {Padua, Italy},
series = {SIGIR '25},
pdf = {magnossaoangel2025effectsLLMPersonas_paper.pdf},
poster = {magnossaoangel2025effectsLLMPersonas_poster.pdf}
}

@inproceedings{pathiyancherumanal2024investigatingbiasinscs,
author = {Pathiyan Cherumanal, Sachin and Scholer, Falk and Trippas, Johanne R and Spina, Damiano},
title = {Towards Investigating Biases in Spoken Conversational Search},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686215.3690156},
doi = {10.1145/3686215.3690156},
abstract = {Voice-based systems like Amazon Alexa, Google Assistant, and Apple Siri, along with the growing popularity of OpenAI's ChatGPT and Microsoft's Copilot, serve diverse populations, including visually impaired and low-literacy communities. This reflects a shift in user expectations from traditional search to more interactive question-answering models. However, presenting information effectively in voice-only channels remains challenging due to their linear nature. This limitation can impact the presentation of complex queries involving controversial topics with multiple perspectives. Failing to present diverse viewpoints may perpetuate or introduce biases and affect user attitudes. Balancing information load and addressing biases is crucial in designing a fair and effective voice-based system. To address this, we (i) review how biases and user attitude changes have been studied in screen-based web search, (ii) address challenges in studying these changes in voice-based settings like SCS, (iii) outline research questions, and (iv) propose an experimental setup with variables, data, and instruments to explore biases in a voice-based setting like Spoken Conversational Search.},
booktitle = {Companion Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {61-66},
numpages = {6},
keywords = {audio output, bias, conversational search, information retrieval},
location = {San Jose, Costa Rica},
series = {ICMI Companion '24},
pdf = {pathiyancherumanal2024investigatingbiasinscs_paper.pdf},
poster = {pathiyancherumanal2024investigatingbiasinscs_poster.pdf}
}

@inproceedings{pathiyancherumanal2024podcastmisinformation,
author = {Pathiyan Cherumanal, Sachin and Gadiraju, Ujwal and Spina, Damiano},
title = {Everything We Hear: Towards Tackling Misinformation in Podcasts},
year = {2024},
isbn = {9798400704628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678957.3678959},
doi = {10.1145/3678957.3678959},
abstract = {Advances in generative AI, the proliferation of large multimodal models (LMMs), and democratized open access to these technologies have direct implications for the production and diffusion of misinformation. In this prequel, we address tackling misinformation in the unique and increasingly popular context of podcasts. The rise of podcasts as a popular medium for disseminating information across diverse topics necessitates a proactive strategy to combat the spread of misinformation. Inspired by the proven effectiveness of auditory alerts in contexts like collision alerts for drivers and error pings in mobile phones, our work envisions the application of auditory alerts as an effective tool to tackle misinformation in podcasts. We propose the integration of suitable auditory alerts to notify listeners of potential misinformation within the podcasts they are listening to, in real-time and without hampering listening experiences. We identify several opportunities and challenges in this path and aim to provoke novel conversations around instruments, methods, and measures to tackle misinformation in podcasts.},
booktitle = {Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {596-601},
numpages = {6},
keywords = {Auditory Interventions, Misinformation, Podcasts},
location = {San Jose, Costa Rica},
series = {ICMI '24},
pdf = {pathiyancherumanal2024podcastmisinformation_paper.pdf},
slides = {pathiyancherumanal2024podcastmisinformation_slides.pdf},
video = {https://youtu.be/n0Ug8ZnjduE?si=HqoPRGOlnQu7RHAm&t=113}
}

@inproceedings{ji2024towardsbiasscs,
author = {Ji, Kaixin and Pathiyan Cherumanal, Sachin and Trippas, Johanne R. and Hettiachchi, Danula and Salim, Flora D. and Scholer, Falk and Spina, Damiano},
title = {Towards Detecting and Mitigating Cognitive Bias in Spoken Conversational Search},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680245},
doi = {10.1145/3640471.3680245},
abstract = {Spoken Conversational Search (SCS) poses unique challenges in understanding user-system interactions due to the absence of visual cues, and the complexity of less structured dialogue. Tackling the impacts of cognitive bias in today’s information-rich online environment, especially when SCS becomes more prevalent, this paper integrates insights from information science, psychology, cognitive science, and wearable sensor technology to explore potential opportunities and challenges in studying cognitive biases in SCS. It then outlines a framework for experimental designs with various experiment setups to multimodal instruments. It also analyzes data from an existing dataset as a preliminary example to demonstrate the potential of this framework and discuss its implications for future research. In the end, it discusses the challenges and ethical considerations associated with implementing this approach. This work aims to provoke new directions and discussion in the community and enhance understanding of cognitive biases in Spoken Conversational Search.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {10},
numpages = {10},
keywords = {Cognitive Bias, Experimental Design, Information Seeking, Physiological Signals, Spoken Conversational Search, Wearable Sensors},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct},
pdf = {ji2024towardsbiasscs_paper.pdf},
poster = {ji2024towardsbiasscs_poster.pdf},
video = {https://drive.google.com/file/d/1yn_OZRtFfOU6cHM_ZOxXQA-EH06I4WCW/view?usp=share_link}
}


@inproceedings{pathiyancherumanal2024walert,
author = {Pathiyan Cherumanal, Sachin and Tian, Lin and Abushaqra, Futoon M. and Magnoss\~{a}o de Paula, Angel Felipe and Ji, Kaixin and Ali, Halil and Hettiachchi, Danula and Trippas, Johanne R. and Scholer, Falk and Spina, Damiano},
title = {Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638309},
doi = {10.1145/3627508.3638309},
abstract = {Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals’ practical needs, and foster a collaborative environment. The data and code of the demo are available at&nbsp;https://github.com/rmit-ir/walert.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {401-405},
numpages = {5},
keywords = {conversational information seeking, large language models, retrieval-augmented generation},
location = {Sheffield, United Kingdom},
series = {CHIIR '24},
pdf = {pathiyancherumanal2024walert_paper.pdf},
poster = {pathiyancherumanal2024walert_poster.pdf},
video = {https://drive.google.com/file/d/1QN8XVjBNKAZ06S1D6VkCcng1ej6giFE-/view?usp=share_link},
demo = {https://www.youtube.com/shorts/V6z8OhSM8cg}
}

@inproceedings{frummet2024ReportSCAI2024,
author = {Frummet, Alexander and Papenmeier, Andrea and Fr\"{o}be, Maik and Kiesel, Johannes and Adlakha, Vaibhav and Braunschweiler, Norbert and Dubiel, Mateusz and Ghosh, Satanu and Gohsen, Marcel and Kreutz, Christin and Momeni, Milad and Nilles, Markus and Cherumanal, Sachin Pathiyan and Pirmoradi, Abbas and Thomas, Paul and Trippas, Johanne R. and Zelch, Ines and Zendel, Oleg},
title = {Report on the 8th Workshop on Search-Oriented Conversational Artificial Intelligence (SCAI 2024) at CHIIR 2024},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3687273.3687282},
doi = {10.1145/3687273.3687282},
abstract = {Conversational Agents are increasingly integrated into our daily routines, assisting us with various tasks, from simple commands such as scheduling events to more complex conversational search interactions. Such conversational search systems are traditionally evaluated with word-overlap metrics such as F1 score and accuracy. The full-day workshop on Search-Oriented Conversational Artificial Intelligence (SCAI) at CHIIR 2024 explored the evaluation of conversational search systems from the user's perspective. This interactive workshop included multiple panel discussions and working groups focused on developing and discussing innovative, user-centered evaluation methods for these systems. This paper, co-authored by both organizers and participants of the workshop, presents a summary of the insights gathered from the panel discussions and working groups.Date: 14 March 2024.Website: https://scai.info/scai-2024/.},
journal = {SIGIR Forum},
month = aug,
pages = {1-12},
numpages = {12},
pdf = {frummet2024ReportSCAI2024_paper.pdf}
}

@inproceedings{pathiyancherumanal2023rmit_ir,
  title={RMIT\_IR at the NTCIR-17 FairWeb-1 Task},
  author={Pathiyan Cherumanal, Sachin and Ji, Kaixin and Hettiachchi, Danula and Trippas, Johanne R and Scholer, Falk and Spina, Damiano},
  booktitle={The Seventeenth NTCIR Conference on Evaluation of Information Access Technologies Proceedings},
  url={https://repository.nii.ac.jp/record/2001315/files/04-NTCIR17-FAIRWEB-CherumanalS.pdf},
  abstract={This report describes the participation of the RMIT IR group at the NTCIR-17 FairWeb-1 task. We submitted five runs with the aim of exploring the role of explicit search result diversification (SRD) and ranking fusion to generate fair rankings considering multiple fairness attributes. We also explored the use of a linear combination-based technique (LC) to take into consideration the relevance while re-ranking. In this report, we compared results from all our submitted runs against each other and the retrieval baselines along each topic type separately (i.e., Researcher, Movie, YouTube). Overall, our results show that neither the SRD-based runs nor the linear combination-based runs show any statistically significant improvement over the retrieval baselines.},
  year={2023},
  address = {Tokyo, Japan},
  series = {NTCIR '23},
  pdf={pathiyancherumanal2023rmit_ir_paper.pdf},
  poster={pathiyancherumanal2023rmit_ir_poster.pdf},
  video={https://youtu.be/VAJCDkbBDQk?si=mfoKheq_xyt2mT53},
  code={https://github.com/rmit-ir/fairweb-1}
}

@inproceedings{pathiyancherumanal2022rmit,
  title={RMIT CIDDA IR at the TREC 2022 Fair Ranking Track},
  author={Pathiyan Cherumanal, Sachin and Alaofi, Marwah and Altalhi, Reham Abdullah and Naghizade, Elham and Scholer, Falk and Spina, Damiano},
  booktitle={The Thirty-First Text REtrieval Conference (TREC 2022) Proceedings},
  abstract={This report describes the participation of the RMIT CIDDA IR group at the TREC 2022 Fair Ranking Track (Task 1). We submitted 8 runs with the aim to explore the role of explicit search result diversification, ranking fusion, and the use of a multi-criteria decision-making method to generate fair rankings considering multiple protected attributes.},
  year={2022},
  series = {TREC '22},
  url={https://trec.nist.gov/pubs/trec31/papers/rmit_cidda_ir.F.pdf},
  pdf={pathiyancherumanal2022rmit_paper.pdf}
}

@inproceedings{pathiyancherumanal2022dc,
author = {Pathiyan Cherumanal, Sachin},
title = {Fairness-Aware Question Answering for Intelligent Assistants},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531682},
doi = {10.1145/3477495.3531682},
abstract = {Conversational intelligent assistants, such as Amazon Alexa, Google Assistant, and Apple Siri, are a form of voice-only Question Answering (QA) system and have the potential to address complex information needs. However, at the moment they are mostly limited to answering with facts expressed in a few words. For example, when a user asks Google Assistant if coffee is good for their health, it responds by justifying why it is good for their health without shedding any light on the side effects coffee consumption might have citegao2020toward. Such limited exposure to multiple perspectives can lead to change in perceptions, preferences, and attitude of users, as well as to the creation and reinforcement of undesired cognitive biases. Getting such QA systems to provide a fair exposure to complex answers -- including those with opposing perspectives -- is an open research problem. In this research, I aim to address the problem of fairly exposing multiple perspectives and relevant answers to users in a multi-turn conversation without negatively impacting user satisfaction.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3492},
numpages = {1},
keywords = {information retrieval, fairness, conversational search},
location = {Madrid, Spain},
series = {SIGIR '22},
pdf = {pathiyancherumanal2022dc_paper.pdf}
}

@inproceedings{pathiyancherumanal2021rmit,
 abstract = {This report describes the data, the assumptions, methodology, and our results involved in the participation at the TREC 2021 Fair Ranking Track. While most of the fairness-aware re-ranking techniques require explicitly defining protected attributes, we tried to leverage the implicit features of the Wikimedia articles by using an implicit diversification technique to study the impact of diversification on a fair ranking problem.},
 author = {Pathiyan Cherumanal, Sachin and Spina, Damiano and Scholer, Falk and Croft, W. Bruce},
 booktitle = {The Thirtieth Text REtrieval Conference (TREC 2021) Proceedings},
 title = {RMIT at TREC 2021 Fair Ranking Track},
 url={https://trec.nist.gov/pubs/trec30/papers/RMIT-IR-F.pdf},
 year = {2022},
 series = {TREC '21},
 pdf = {pathiyancherumanal2021rmit_paper.pdf},
 poster = {pathiyancherumanal2021rmit_poster.pdf}
}

@inproceedings{pathiyancherumanal2021evaluatingfairness,
author = {Pathiyan Cherumanal, Sachin and Spina, Damiano and Scholer, Falk and Croft, W. Bruce},
title = {Evaluating Fairness in Argument Retrieval},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482099},
doi = {10.1145/3459637.3482099},
abstract = {Existing commercial search engines often struggle to represent different perspectives of a search query. Argument retrieval systems address this limitation of search engines and provide both positive (PRO) and negative (CON) perspectives about a user's information need on a controversial topic (e.g., climate change). The effectiveness of such argument retrieval systems is typically evaluated based on topical relevance and argument quality, without taking into account the often differing number of documents shown for the argument stances (PRO or CON). Therefore, systems may retrieve relevant passages, but with a biased exposure of arguments. In this work, we analyze a range of non-stochastic fairness-aware ranking and diversity metrics to evaluate the extent to which argument stances are fairly exposed in argument retrieval systems.Using the official runs of the argument retrieval task Ttouch\'{e} at CLEF 2020, as well as synthetic data to control the amount and order of argument stances in the rankings, we show that systems with the best effectiveness in terms of topical relevance are not necessarily the most fair or the most diverse in terms of argument stance. The relationships we found between (un)fairness and diversity metrics shed light on how to evaluate group fairness -- in addition to topical relevance -- in argument retrieval settings.},
booktitle = {Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
pages = {3363-3367},
numpages = {5},
keywords = {fairness, evaluation, argument retrieval},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21},
pdf = {pathiyancherumanal2021evaluatingfairness_paper.pdf},
poster = {pathiyancherumanal2021evaluatingfairness_poster.pdf},
code = {https://github.com/sachinpc1993/fair-arguments}
}

@article{spina2021futureconversationsreport,
author = {Spina, Damiano and Trippas, Johanne R. and Thomas, Paul and Joho, Hideo and Bystr\"{o}m, Katriina and Clark, Leigh and Craswell, Nick and Czerwinski, Mary and Elsweiler, David and Frummet, Alexander and Ghosh, Souvick and Kiesel, Johannes and Lopatovska, Irene and McDuff, Daniel and Meyer, Selina and Mourad, Ahmed and Owoicho, Paul and Cherumanal, Sachin Pathiyan and Russell, Daniel and Sitbon, Laurianne},
title = {Report on the future conversations workshop at CHIIR 2021},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3476415.3476421},
doi = {10.1145/3476415.3476421},
abstract = {The Future Conversations workshop at CHIIR'21 looked to the future of search, recommendation, and information interaction to ask: where are the opportunities for conversational interactions? What do we need to do to get there? Furthermore, who stands to benefit?The workshop was hands-on and interactive. Rather than a series of technical talks, we solicited position statements on opportunities, problems, and solutions in conversational search in all modalities (written, spoken, or multimodal). This paper -co-authored by the organisers and participants of the workshop- summarises the submitted statements and the discussions we had during the two sessions of the workshop. Statements discussed during the workshop are available at https://bit.ly/FutureConversations2021Statements.},
journal = {SIGIR Forum},
month = jul,
articleno = {6},
numpages = {22},
pdf = {spina2021futureconversationsreport_paper.pdf}
}

@inProceedings{bindukr2017coldstartproblem,
author="Bindu, K. R.
and Visweswaran, Rhama Lalgudi
and Pathiyan Cherumanal, Sachin
and Solai, Kundavai Devi
and Gunasekaran, Soundarya",
title="Reducing the Cold-User and Cold-Item Problem in Recommender System by Reducing the Sparsity of the Sparse Matrix and Addressing the Diversity-Accuracy Problem",
booktitle="Proceedings of International Conference on Communication and Networks",
year="2017",
publisher="Springer Singapore",
address="Singapore",
pages="561--570",
abstract="Recommender Systems are a subclass of information filtering systems that seek to predict the preferences of a user or the preference that a user would give to an item. The most common problem faced by these systems is the lack of data. Such a situation leads to a matrix that is extremely sparse thus reducing the accuracy of prediction. Cold-start problem is one such problem that is faced by the recommender systems when a new user or a new item enters the system. We are hoping to reduce the cold-user and the cold-item problem by reducing the sparsity of the sparse matrix with the help of Iterative Local Least Squares algorithm and a hybrid of Heat Spreading algorithm and Probability Spreading algorithm.",
isbn="978-981-10-2750-5"
}